# ğŸ§  Automated Fact-Checking Prediction Using Machine Learning

![Pinocchio](./politifact.png)




## ğŸ” Project Overview

In an era of viral misinformation, this project aims to build an **automated fact-checking system** using machine learning. Leveraging labeled claims from [PolitiFact.com](https://www.politifact.com/), the model classifies public statements into six credibility levels:  
**True**, **Mostly True**, **Half True**, **Mostly False**, **False**, and **Pants on Fire**.

The final model was deployed using FastAPI and Google Cloud, offering a user-facing interface to assess the credibility of new claims.

ğŸŒ **Live App**: [Try the Fact-Checker â†’](https://fastapi-app-273008876300.us-central1.run.app/)

---

## ğŸ“‚ Table of Contents

- [ğŸ“„ Source Data](#source-data)
- [ğŸ“š Notebooks](#notebooks)
- [ğŸ“‘ Documents](#documents)
- [âš™ï¸ Model Overview](#model-overview)
- [ğŸš€ Deployment](#deployment)
- [ğŸ› ï¸ Future Work](#future-work)

---

## ğŸ“„ Source Data

- **Original Labeled Statements**: Scraped from [PolitiFact.com](https://www.politifact.com/)
- **Metadata Includes**:
  - Statement text
  - Speaker/source
  - Statement date
  - Labeled credibility (by human fact-checkers)

---

## ğŸ“š Notebooks

- `EDA.ipynb` â€” Data Wrangling & Visualization  
- `ML.ipynb` â€” Model Training and Evaluation  
- `Evaluation_Report-3.ipynb` â€” Final Model Interpretation  
- `Fine_Tuning.ipynb` â€” GridSearchCV and Hyperparameter Tuning  
- `Flask.ipynb` â€” First Deployment Steps  
- `Deep_Learning.ipynb` â€” Experimentation with DNN  
- `Trees_and_Forests.ipynb` â€” Tree-based Models  
- `Recommendation_Engines.ipynb` â€” Auxiliary ML Exploration

_Notebooks not used in final deployment are stored in the `extras/` folder._

---

## ğŸ“‘ Documents

- ğŸ“˜ [Final Report (PDF)](./Automated%20Fact-Checking%20Prediction%20Using%20Machine%20Learning.pdf)

  Detailed explanation of methodology, challenges, and findings.

- ğŸ–¥ï¸ Slide Deck (coming soon)

---

## âš™ï¸ Model Overview

- Models Tested: Naive Bayes, Logistic Regression, SVM, XGBoost, Random Forest
- Best Model: **Logistic Regression** (Macro AUC = 0.7485)
- Key Features:
  - Cleaned and tokenized statements
  - One-hot encoded source categories
  - Temporal patterns from publication dates
- Interpretability:
  - Predictive word analysis using conditional probability with smoothing
  - Clear association between certain terms and credibility labels

---

## ğŸš€ Deployment

The final model is deployed on Google Cloud Run using FastAPI:

ğŸŒ [Access the Deployed App](https://fastapi-app-273008876300.us-central1.run.app/)

---

## ğŸ› ï¸ Future Work

- Automate real-time data scraping from PolitiFact
- Implement NER for better speaker/source classification
- Explore transformer-based architectures like BERT for deeper language understanding

---

## ğŸ“¸ Acknowledgments

- Data Source: [PolitiFact.com](https://www.politifact.com/)


---

